{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First model training\n",
        "\n",
        "We retrieve the pre-trained model `YOLO11n` (yolo11n.pt) from the `YOLO` class in the `ultralytics` module. For this first training run, we only run 3 epochs to see if it works.\n",
        "\n",
        "This first step is intended to be performed only once. The rest of the training will be carried out using the `model_training.py` script in the `scripts` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "#PROJECT_PATH = '/content/drive/MyDrive/b2/Data/Achieving a ML Proof-of-Concept'\n",
        "PROJECT_PATH = os.getcwd().split('notebooks')[0]\n",
        "LABEL_PATH = os.path.join(PROJECT_PATH, 'data', 'augmented_train', 'labels')\n",
        "\n",
        "# get the number of classes\n",
        "nb_class, classes = 0, []\n",
        "for filename in os.listdir(LABEL_PATH):\n",
        "    with open (os.path.join(LABEL_PATH, filename), 'r') as f:\n",
        "        class_ids = [line.split()[0] for line in f.readlines()]\n",
        "        for class_id in class_ids:\n",
        "            if class_id not in classes:\n",
        "                classes.append(class_id)\n",
        "                nb_class += 1\n",
        "\n",
        "# create the dataset using yaml format (required by YOLO)\n",
        "dataset_config = {\n",
        "    'path': PROJECT_PATH,\n",
        "    'train': 'data/augmented_train/images',\n",
        "    'val': 'data/valid/images',\n",
        "    'test': 'data/test/images',\n",
        "    'names': {0: 'hold'}\n",
        "}\n",
        "\n",
        "CONFIG_PATH = os.path.join(PROJECT_PATH, 'data', 'augmented_train', 'data.yaml')\n",
        "with open(CONFIG_PATH, 'w') as f:\n",
        "    yaml.safe_dump(dataset_config, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yj0f4vhtX5SA",
        "outputId": "1ea1dfbe-5b0d-4e21-d73c-c7a4bc99db55"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# load the model and set the best possible device\n",
        "model = YOLO('yolo11n.pt')\n",
        "device = torch.device(\n",
        "    'cuda' if torch.cuda.is_available()              # cuda for NVIDIA GPUs\n",
        "    else 'mps' if torch.backends.mps.is_available()  # mps for Apple silicon\n",
        "    else 'cpu')                                      # cpu otherwise\n",
        "\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the model\n",
        "results = model.train(\n",
        "    data=CONFIG_PATH,\n",
        "    epochs=3,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# paths\n",
        "TEST_DIR = os.path.join(PROJECT_PATH, 'data', 'test')\n",
        "TEST_IMAGE_DIR = os.path.join(TEST_DIR, 'images')\n",
        "TEST_LABEL_DIR = os.path.join(TEST_DIR, 'labels')\n",
        "image_files = sorted([f for f in os.listdir(TEST_IMAGE_DIR) if f.endswith('.jpg')])\n",
        "\n",
        "# read YOLO labels\n",
        "def read_yolo_labels(label_path, img_width, img_height):\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                data = line.strip().split()\n",
        "                class_id = int(data[0])\n",
        "                \n",
        "                x_center, y_center, width, height = map(float, data[1:5]) # center_x, center_y, width, height\n",
        "\n",
        "                # convert to pixel coordinates\n",
        "                x = int((x_center - width/2) * img_width)\n",
        "                y = int((y_center - height/2) * img_height)\n",
        "                w = int(width * img_width)\n",
        "                h = int(height * img_height)\n",
        "\n",
        "                boxes.append((x, y, w, h))\n",
        "    return boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "fig, axes = plt.subplots(6, 2, figsize=(6.4, 4.8*4))\n",
        "\n",
        "for ax, title in zip(axes[0], ['Predictions', 'Ground Truth']):\n",
        "    ax.set_title(title, fontsize=16)\n",
        "\n",
        "for i, img_file in enumerate(image_files[:6]):\n",
        "    img_path = os.path.join(TEST_IMAGE_DIR, img_file)\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    # prédictions\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].axis('off')\n",
        "    results = model.predict(img_path, conf=0.3)\n",
        "\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = float(box.conf[0])\n",
        "            \n",
        "            # ajoute la boîte avec score de confiance\n",
        "            axes[i, 0].add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                fill=False, edgecolor='red', linewidth=2))\n",
        "            axes[i, 0].text(x1, y1-5, f'{conf:.2f}', \n",
        "                          color='red', fontsize=8, backgroundcolor='white')\n",
        "\n",
        "    # vérité terrain\n",
        "    axes[i, 1].imshow(img)\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    label_path = os.path.join(TEST_LABEL_DIR, f'{os.path.splitext(img_file)[0]}.txt')\n",
        "    gt_boxes = read_yolo_labels(label_path, img_width, img_height)\n",
        "\n",
        "    for x, y, w, h in gt_boxes:\n",
        "        axes[i, 1].add_patch(plt.Rectangle((x, y), w, h,\n",
        "                             fill=False, edgecolor='green', linewidth=2))\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# save the model and the figure comparing predictions and ground truth\n",
        "now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n",
        "model.save(os.path.join(PROJECT_PATH, 'models', f'{now}_yolo11n.pt'))\n",
        "fig.savefig(os.path.join(PROJECT_PATH, 'models', f'{now}_predictions.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
